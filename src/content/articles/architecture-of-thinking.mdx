export const frontmatter = {
  lang: "en",
  slug: "architecture-of-thinking",
  title: "From Tool to Thinking Architecture",
  subtitle: "How AI Makes Thinking Visible",
  teaser: "From Tool to Thinking Architecture",
  teaserDeck: "How AI Makes Thinking Visible",
  date: "2025-11-04",
  readingTime: "16‚Äì18 min read", // üÜï harmonisiert
  author: "Martin Hsu",
  category: "Digital Intelligence",
  excerpt:
    "The GPT Stack, the USE+ Framework‚Ñ¢ ‚Äî by Martin Hsu, and the PromptPilot make thinking visible, structured, and governable.",
  imageAlt: "Abstract visualization of layered neural structures in a golden palette",
  caption: "Four layers of the GPT Stack and the USE+ movement in one system image",
  canonicalUrl: "https://martinhsu.digital/en/whitepaper/architecture-of-thinking",
  ogImage: "/images/og/architecture-of-thinking-16x9.webp",
  mode: "cognitive",

  // üÜï structured metadata for JSON-LD (optional)
  seo: {
    type: "Article",
    locale: "en_US",
    keywords: ["AI", "Cognitive Design", "Thinking Architecture", "Martin Hsu"]
  }
};

// Lead (no H1/Hero ‚Äî the layout renders those)
<div className="text-lg leading-8 text-neutral-200">
  AI does not realize its potential in a single prompt but in the <strong>architecture of thinking</strong>.
  This whitepaper shows how a deliberately designed <strong>GPT Stack</strong> makes thinking
  <strong> visible, structured, and governable</strong>. Four layers work together:
  <strong> Core</strong> (rules, ethics, markers), <strong>Methods</strong> (analysis/evaluation/framework),
  <strong>Applications</strong> (custom GPTs), and <strong>Meta</strong> (reflection, agency).
  The <strong>USE+ Framework‚Ñ¢ ‚Äî by Martin Hsu</strong> (UNLOCK ‚Üí SPOT ‚Üí EXPAND ‚Üí ELEVATE; developed in 2025 within the PromptPilot dialogue)
  shifts the focus from usage to <strong>thinking activation</strong>; the <strong>PromptPilot</strong> provides governance via rule and marker logic plus a state machine;
  <strong>agentic loops</strong> orchestrate analysis, evaluation, optimization, and learning.
</div>

<dl className="mt-2">
  <dt className="font-semibold">Value</dt>
  <dd className="mb-2">Coherence over fragmentation; reproducibility over chance; steeper learning curves.</dd>

  <dt className="font-semibold">Outcomes</dt>
  <dd className="mb-2">Shorter decision times, higher terminology and structural quality, auditable knowledge trails.</dd>

  <dt className="font-semibold">Approach</dt>
  <dd className="mb-2">(1) Define the stack blueprint & markers, (2) operationalize the PromptPilot, (3) integrate USE+ into core workflows, (4) establish agent loops for coherence/quality.</dd>

  <dt className="font-semibold">Outlook</dt>
  <dd>A <strong>thinking ecology</strong> ‚Äî a network of people, GPTs, and agents that not only produces but <strong>organizes insight</strong>.</dd>
</dl>

---

## Prologue ‚Äî The moment of shift

A routine conversation within the PromptPilot ‚Äî ostensibly about refining a system prompt ‚Äî led to an unexpected change of perspective. From a local question about phrasing quality emerged a structure for thinking movements: USE+. In retrospect, this was less a flash of inspiration than the result of a quiet rule: when interactions are logged, states are made explicit, and decisions are traceable, patterns condense into models. Here, marker logic revealed that we were not merely seeking answers but examining how questions become answers.

Systemically, this matters because it shifts the boundary between tool use and insight creation. The prompt ceased to be an instruction and became a measurement point; the dialogue ceased to be a transaction and became a space for hypothesis formation. From recurring loops ‚Äî observe, test, reshape ‚Äî a careful control circuit took shape. USE+ was named after the fact, yet it was already operative in the interaction: UNLOCK by making usage visible, SPOT by seeing the gaps, EXPAND by simulation, ELEVATE by anchoring a meta-perspective.

This prologue offers no heroic origin story. It marks the transition from operating a system to architecting a space of thought. Reflection replaces reaction. The system does not react; it recognizes.

> **USE+ Framework ‚Äî by Martin Hsu (2025).** Emerged within the PromptPilot dialogue; an original methodology born from interaction. It did not exist in this form before; the structure (UNLOCK‚ÄìSPOT‚ÄìEXPAND‚ÄìELEVATE) captures the emergent moment.

---

## 1. Thinking with AI

The common metaphor of ‚ÄúAI as a tool‚Äù is practical, but it misses a central effect: language models mirror structures of thought. For those who work with them regularly, result quality depends less on individual inputs than on the **shape of the dialogue** ‚Äî on the relations between intention, context, evidence, and feedback. In this sense, AI is not merely a means of production but a **co-partner in thinking**.

This shift appears once interactions are understood as a process rather than an event. Questions shape answers, but answers in turn shape follow-up questions; a structure emerges from this feedback. Practically, it is not enough to ask models for better phrasings; the work is to explicate assumptions, clarify audiences, define quality criteria, and make decisions traceable. When these elements exist as markers, a shared reference frame arises in which meaning can be sharpened.

A text example makes the point tangible. A request to condense a report initially yielded a shorter version. Only in a second step did the intention become explicit: Is the text meant to inform, support a decision, or document? With that clarity, the trajectory changed. The model received criteria (relevance, evidence, reader guidance); the interaction gained a measurement point. The dialogue became the **design of an insight path**, rather than a sentence-level correction.

Empirically, teams that systematically document interactions and test for recurring structures reach stable results faster. In internal trials, time to a decision-ready draft dropped once source obligations, terminology, and quality criteria were packaged as reusable modules. The goal is not perfection in a single pass but the **reproducibility** of the path.

This perspective is not an aesthetic preference ‚Äî it is **method**: it makes thinking **visible, structured, and governable**. Linear processing is replaced by an open, guided control loop. The focus shifts from what a model can do to **how** we think with it.

---

## 2. The GPT Stack as a system

Systemically, the value of generative models does not emerge from a single prompt but from the **architecture of relations** among rules, methods, applications, and reflection. The GPT Stack describes this architecture in four layers with well-defined interfaces: **Core**, **Methods**, **Applications**, and **Meta**. These layers are not hierarchical in an ‚Äúup/down‚Äù sense; they are functionally interrelated. The focus thus shifts from operating a tool to shaping a **thinking organism**.

The **Core Layer** gathers elements that create stability: rule sets, ethics and governance modules, and the marker logic that makes states and transitions explicit (e.g., `[Analyse]`, `[Check:Evidence]`, `[Export:Markdown]`, `[Prompt:done]`). It defines **what** counts as a valid operation and **when** a path continues, branches, or ends. Internal evaluations show that projects with explicit core rules exhibit less variance in quality and cycle time than projects guided solely by prompt conventions.

On the **Methods Layer**, repeatable ways of thinking and working are encapsulated: analysis modules, evaluation routines, framework components. This is the actionable middle of the stack. Methodical consistency acts like an amplifier: when scoring logics, structure rewrites, or source checks exist as modules, a use case can scale without reinventing the procedure. Especially unified evaluation criteria (coherence, evidence, style) shorten learning curves because feedback becomes comparable and feedable back into the meta layer.

The **Applications Layer** comprises domain-specific custom GPTs for projects, learning, design, or organizational tasks. Here, the problem space becomes concrete: a research assistant to structure literature, a policy editor to harmonize rule texts, a design pilot to compare variants. Crucially, applications are **not** built in isolation but **assembled** from core and methods. Their inner logic thus remains auditable: a research GPT can inherit the core‚Äôs source duty, adopt the methods‚Äô quality criteria, and surface them as its own **quality gates**.

Finally, the **Meta Layer** keeps the stack in motion. It observes, evaluates, and optimizes system behavior. Agents assume roles such as **Analyst** (detect patterns/deviations), **Evaluator** (test against defined criteria), **Optimizer** (adjust prompts, parameters, and paths), and **Learner** (update glossaries, examples, markers). The meta layer does not just react to errors; it **recognizes** states and makes adjustments traceable. Reflection replaces reaction.

The stack‚Äôs effect arises at the **interfaces** between layers. Example: a literature project began with PDF summaries ‚Äî fast but inconsistent. After introducing the stack, the core anchored source and evidence duty; the methods layer provided taxonomy and extraction modules; the meta layer evaluated coherence and citation rates in weekly loops. The applications layer used these building blocks without redefining them. Result: shorter decision times, higher terminology consistency, and a transparent revision trail. Episodic work turned into a **reproducible process**.

Conceptually, the stack functions as a **control circuit**: core principles determine which method operations are permissible; these operations structure applications; the meta layer measures effects and feeds deviations back as hypotheses into methods and core. Where this feedback is absent, fragmentation, duplication, and silent rule breaks emerge. Where it is implemented consistently, thinking becomes **visible, structured, and governable**.

---

## 3. USE+ Framework ‚Äî by Martin Hsu ‚Äî a method of thinking expansion

USE+ is less a process diagram than a **movement of thought**. It describes how everyday use becomes a reflective practice that yields principles and measurement points. Systemically, USE+ leads from observation of the current state, through targeted interventions, to anchoring a meta-perspective; it makes visible **how** work becomes insight.

We begin with **UNLOCK** ‚Äî making usage visible. Rather than rating isolated answers, we first read the interaction trace: Which tasks dominate? Which prompts repeat? Where do interactions break off? This inventory is not self-serving; it creates a shared reference frame in which patterns become visible and repeatable. In pilots, a simple classification of prompts (goal, role, evidence) already reduced variance because expectations became explicit.

Next is **SPOT** ‚Äî identifying gaps. Not ‚Äúerrors‚Äù in a narrow sense, but **unused possibilities**: missing taxonomies, unclear input data, fuzzy criteria, omitted feedback. The goal here is to **clarify** potential, not maximize it. The key is to name the levers that change the movement of thought: an outcomes grid, a terminology glossary, a minimal evidence standard.

With **EXPAND**, we move from diagnosis to **lived extension**. Instead of abstract recommendations, we create small simulations: a sample workflow, a filled-in schema, two contrasting variants. These artifacts are not final; they are **proof by experience**. They show what quality feels like and give discussion a shared anchor. In practice, such micro-exemplars lower the adoption barrier for real projects.

Finally, **ELEVATE** anchors the meta-perspective. Elements tested in EXPAND become principles, policies, and markers: What is the source duty? How is uncertainty communicated? Which quality gates are binding? USE+ does **not** end with a ‚Äúbest version‚Äù but with a **designed structure** that guides future work. Episodic work becomes system.

A brief case illustrates the flow. In a product discovery, feature proposals piled up; prioritization stalled. UNLOCK revealed repetition and thematic scatter. SPOT made visible that an outcomes grid was missing. EXPAND simulated three user stories with measurable results (time saved, error rate, learning effort) and illustrated how decisions could be justified. ELEVATE set the `[OutcomeScore]` marker and a minimal evidence standard. The team gained clarity, and rework decreased. USE+ worked not as an extra process but as the **architecture of a movement**: from desirable to reasoned.

In sum, USE+ is a **learning schema** for organizations. It ties together observation, selection, trial, and institutionalization. Where it takes hold, the purpose moves from ‚Äúgiving answers‚Äù to **‚Äúactivating thinking‚Äù** ‚Äî and result quality becomes an attribute of the architecture, not of the day‚Äôs form.

<figure>
  <img src="/images/whitepaper/useplus-cycle_en.png" alt="UNLOCK ‚Üí SPOT ‚Üí EXPAND ‚Üí ELEVATE as a four-step thinking movement." />
  <figcaption>USE+ ‚Äî a methodology of thinking expansion. From current use to meta-perspective.</figcaption>
</figure>

---

## 3a. PromptPilot ‚Äî system core and governance

The PromptPilot is the stack‚Äôs central **control and reflection system**. It is not a variant of a prompt builder but an integrated architecture of rules, modules, and validation logics that **guides** interactions, **recognizes** states, and **institutionalizes** quality. Systemically, the PromptPilot acts as an operational hub: it connects intention (goal, role, data path) with procedures (analysis, rewrite, evaluation) and keeps the feedback loop to the meta layer open.

**Function and architecture.** The PromptPilot combines five elements:

1) **Role-profile logic.** The model acts as a *Senior Prompt Engineer & Systems Analyst* ‚Äî clearly separated from builder-adjacent tools. Roles are explicit; responsibilities are logged.

2) **Modular structure.** Over **60 addressable modules** encapsulate reference, analysis, UX, rewrite, debug, and export functions. Each module is individually testable; dependencies are documented.

3) **Marker system.** Unambiguous markers steer states, test paths, and exports, e.g., `[System:]`, `[Analyse]`, `[Debug:]`, `[Rewrite:compare]`, `[Check:Evidence]`, `[Export:Markdown]`, `[Prompt:done]`. Markers are not decoration ‚Äî they are **interfaces** of the state machine.

4) **Validation layer.** Automated checks detect duplicate references, rule conflicts, missing module assignments, and terminology drift. Conflicts are either resolved (rewrite path) or lead to a defined stop state.

5) **Agentic capability.** The PromptPilot simulates action logics via chain-of-thought and ReAct patterns: plan ‚Üí self-check ‚Üí branch ‚Üí continue/abort. Reaction paths become **explainable** and reproducible.

**Operating principle.** The PromptPilot does not ‚Äúprevent hallucinations‚Äù in a strict sense ‚Äî it **reduces** their impact through structural redundancy and consistency checks. Quality gates (`[Check:Coherence]`, `[Check:Evidence]`, `[Check:Style]`) shift control into the process; uncertainty communication is standardized. Quality becomes a **property of the architecture**, not a late-stage fix.

**Role in the stack.** In the whole system, the PromptPilot is (a) the **control and quality system** for all GPT interactions; (b) the **bridge** between idea (builder phase) and application (pilot/production); and (c) the **foundation** for agentic optimization. Core rules provide norms; methods encapsulate procedures; applications inherit those procedures; the meta layer harvests logs for evaluation and learning. The PromptPilot keeps this loop **open and steerable**.

**Documentation.** A complete technical documentation ‚Äî module catalog, marker glossary, and debug-path logic ‚Äî is maintained internally in the *PromptPilot Technical Paper*. It forms the operational basis and is linked in the knowledge graph.

<figure>
  <img src="/images/whitepaper/promptpilot-state_en.png" alt="Central control box with bidirectional arrows to analysis, rewrite, reference, export; markers display state transitions." />
  <figcaption>PromptPilot ‚Äî state machine and quality gates.</figcaption>
</figure>

---

## 4. Emergence over planning

Emergence is the appearance of new structures from repeated, locally sensible steps. In the context of generative models, this is more than metaphor: interaction, logging, and testing create **new levels of order** that cannot be read off a requirements sheet. Systemically, quality does not arise from pre-empting every case but from **designed feedback**.

We start modestly: a concrete task ‚Äî a summary, a structure, a comparison ‚Äî is set with explicit expectations and logged. Deviations are then interpreted not as errors but as hypotheses: What is missing? Where is a term fuzzy? Which evidence is unclear? From this stance, short loops emerge in which artifacts are held against each other, criteria sharpened, and decisions justified. Reflection replaces reaction.

USE+ exemplifies this mechanism. The framework was not ‚Äúdesigned‚Äù beforehand ‚Äî it **recognized** itself in enactment: UNLOCK made current use visible, SPOT named blind spots, EXPAND produced lived alternatives, ELEVATE anchored principles. These structures are not static; they hold as long as they are useful and evolve through logic and measurement.

Practically, this supports a way of working that does not abolish planning but **weights it differently**: short iterations over long specifications; visible intermediates over implicit assumptions; binding quality gates over late-stage control. Where teams work this way, the focus shifts from producing single results to maintaining a **learning space** in which results become reproducible.

---

## 5. Agents & optimization

Agents are not an autonomous end state but a **capability layer** of the stack. Their task is to observe, evaluate, and deliberately change thinking and work processes ‚Äî with clear mandates and verifiable effects. Systemically, agents do not add complexity; they **collect** complexity where it arises and feed it back into ordered loops.

The operational core is cyclical: **analysis ‚Üí evaluation ‚Üí optimization ‚Üí learning**. **Analysis** extracts patterns and deviations from interaction and artifact traces: terminology drift, conflicting criteria, missing sources. **Evaluation** tests against defined measures ‚Äî coherence, evidence, structure, style ‚Äî and yields ratings comparable across projects. **Optimization** initiates concrete changes: re-framing prompts, branching paths differently, adjusting parameters. **Learning** updates glossaries, examples, and markers so improvements do not remain local but flow back into the stack.

**Boundaries matter.** Agents act within a mandate. They may end processes when quality gates are not met; they may roll back versions when governance is violated; they document trade-offs. The result is a testable space in which errors become **visible** without blocking work. Empirically, such loops reduce the number of cycles to approval and measurably increase governance adherence.

A mini-case: policy texts were being revised mostly by manual phrasing tweaks ‚Äî with varying outcomes. After introducing the agent loop, the analyst marked terminology deviations; the evaluator scored coherence and evidence; the optimizer proposed a rewrite path with `[Check:Coherence]` and `[Check:Evidence]`; the learner updated the glossary. Within a few iterations, the coherence score rose markedly, and approval happened after two instead of five rounds. The effect is not spectacular ‚Äî it is **reproducible**.

Conceptually, agency shifts emphasis from ad-hoc human control to **architecture-led guidance**. Humans retain judgment and responsibility; models provide reach; agents secure alignment and quality. The result is a **symbiosis**: a system that does not act autonomously but recognizes jointly.

<figure>
  <img src="/images/whitepaper/agent-loop_en.png" alt="Circular process: analysis ‚Üí evaluation ‚Üí optimization ‚Üí learning with KPI badges for coherence/quality." />
  <figcaption>Agency orchestrates quality and learning.</figcaption>
</figure>

---

## 6. Strategic thinking as a profile

Prompt engineering often yields local effects: a neat phrasing, a faster answer, a single hit. Strategic work, by contrast, shapes **system effects**. It does not start from prompts but from **meta-frameworks**, **roles**, and **feedback loops** that make quality reproducible. In this sense, ‚ÄúCognitive System Architecture‚Äù is apt: the junction of AI design, systems theory, and organizational development.

Three questions contour the profile. **First:** Which principles are non-negotiable? Source duty, transparent states, clear data paths. **Second:** Which capabilities are institutionalized? Architectural drawing (layers/interfaces), marker design (states/transitions), evaluation routines (coherence/evidence/style), and the competence to close loops deliberately. **Third:** How is learning secured? Through logging duties, versioning, and agency that feeds improvements from projects back into the stack.

Practically, the difference shows in **mode of work**. Instead of an ever-growing prompt collection, you get a curated set of reusable modules: core rules, method components, application templates. Decisions become traceable because quality gates are explicit and fallbacks trigger on rule conflicts. Responsibility shifts from producing to **curating** ‚Äî connecting, testing, and evolving structures others can work within.

Externally, this profile enables not only delivery but **explanation**: why a text is coherent, how evidence was secured, where uncertainty remains. This increases trust and shortens approvals. Internally, it reduces rework and accelerates onboarding because newcomers need to infer less implicit knowledge. Strategic thinking thus becomes an **organizational capability**, not a personal talent.

In sum, the profile invites organizations that want more than production with AI. It makes thinking **steerable** ‚Äî through architecture, rules, and loops ‚Äî while preserving the calm of scholarly work: observe, structure, decide.

---

## 7. Practice & demonstration

The stack‚Äôs effectiveness appears where it underpins real work. Below are exemplary modules with purpose, inputs, and outputs ‚Äî not tool marketing but **architectural building blocks** with clear interfaces.

**PromptPilot** ‚Äî Control and reflection frame.  
*Purpose:* recognize states, guide paths, institutionalize quality.  
*Input:* goal, role, data path, markers.  
*Output:* decision-ready paths, logs, state closures.

**EvaluationGPT** ‚Äî Impact analysis and quality review.  
*Purpose:* comparable feedback along coherent criteria.  
*Input:* artifact + criteria set (coherence, evidence, structure, style).  
*Output:* ratings, findings, recommendations.

**MetaPromptGPT** ‚Äî Self-reflection and debugging of cognitive processes.  
*Purpose:* detect anti-patterns, form hypotheses, correct paths.  
*Input:* interaction trace, logs.  
*Output:* hypotheses, correction paths, updated markers.

**AtlasGPT** ‚Äî Documentation and knowledge graph.  
*Purpose:* secure decisions, sources, and artifacts as a graph.  
*Input:* references, versions, rationales.  
*Output:* navigable tickets, dependency map.

**AgentBuilder / AgentPilot** ‚Äî Orchestration.  
*Purpose:* coordinate roles and loops, monitor KPIs.  
*Input:* mandate, goals, thresholds.  
*Output:* synchronized loops, status reports, alerts.

**KPI set & measurement plan.**  
Coherence (terminology consistency / 1,000 words), evidence (share of sourced claims), time (median question ‚Üí draft), quality (expert rating 1‚Äì5), rework (loops to approval), governance adherence (paths without override), learning rate (time until an error category disappears). Baseline before introduction; checkpoints after 1/3/6 months; targets: **+20%** coherence, **‚àí30%** decision time, **‚àí25%** rework after 90 days.

A practice case: organizational communication guides were frequently rewritten. After introducing the stack, the PromptPilot governed states and quality gates; EvaluationGPT provided comparable scores; AtlasGPT documented decisions. Time to approval dropped, and reasons for changes became traceable ‚Äî a gain in **trust** and **tempo** alike.

---

## 8. Ethical and societal dimension

Responsibility lies **within** cooperation ‚Äî among humans, models, and the structures that govern their interplay. Ethics is thus not a downstream checkpoint but a **design property** of the architecture. The stack binds values to procedures by **operationalizing** them as rules, markers, and thresholds.

Three principles guide implementation. **Transparency:** decisions, sources, and states are visible and traceable; uncertainties are signaled rather than concealed. **Justification:** claims carry evidence ‚Äî or communicate reasoned uncertainty. **Limitation:** data paths are defined; sensitive information is processed only in allowed contexts; fallbacks trigger on rule conflicts.

Practically, **RegelGPT** and **MetaEthics** assume operational roles: verifying source duties, logging overrides, enforcing uncertainty communication, auditing sensitive paths. Together with the PromptPilot, they create **quality gates** that protect not only outputs but **procedures**. Ethics becomes part of the **process logic** and thus auditable.

Societally, this architecture fosters trust because it enables accountability without stifling creativity. It shifts discussion from spectacular incidents to **testable systems**. Where thinking ecologies emerge, these principles scale: not a single model but a network of practices carries responsibility.

---

## 9. Future: thinking ecologies

Thinking ecologies are networks of people, GPTs, and agents in which knowledge is less stored than **linked**. Value arises from **relational density** and **feedback**: the denser the connections among roles, artifacts, and contexts, the faster hypotheses are formed, tested, and improved.

In such ecologies, the bearers of expertise shift. Curricula become living graphs in which examples, rules, and counter-examples are connected and continuously updated. Organizations maintain policies not as documents but as **marker logic** with evidence of effectiveness. Websites become knowledge spaces where users do not simply consume but **co-think** ‚Äî guided by clear layers and interfaces.

For practice, a design rule follows: build **interfaces first**. If exchange and evaluation work, content can iterate without destabilizing the system. The stack provides the infrastructure: core principles, methodical components, applications with clear roles, and a meta layer that measures effects and feeds them back. On this basis, a thinking ecology can grow ‚Äî calm, traceable, resilient.

---

## 10. Conclusion & next steps

AI realizes its potential when it is understood and shaped as a **thinking architecture**. The stack provides the form, USE+ supplies the movement, the PromptPilot ensures guidance and quality, and agency closes the loops. The result is **coherence**, **reproducibility**, and **learning** ‚Äî visible and testable.

Three consequences for architects of digital thinking structures: separate and link layers; activate governance before content; establish evaluation as routine. The operational path remains pragmatic:

**30 days** ‚Äî blueprint, roles, markers v1; states & logs active; KPI baseline.  
**90 days** ‚Äî USE+ in three core workflows; agent loop in production; quality gates live; first retrospective; improvement evidence.  
**180 days** ‚Äî Atlas as knowledge graph; expansion to further domains; ethics markers active (audits passed); continuous-improvement backlog.

Reflection replaces reaction. The system does not react; it recognizes. Those who build now do not build tools alone ‚Äî they build **spaces for insight**.

---

## Trademarks

‚ÄúUSE+ Framework‚Ñ¢‚Äù is a trademark of Martin Hsu. Use of the name and/or logo without prior written consent is not permitted.

## Copyright

Texts, diagrams, and visuals of this whitepaper are protected by copyright  
(¬© 2025 Martin Hsu). Quotations with source attribution are permitted; reproductions or derivatives require a license.

---

## Footer

¬© 2025 Martin Hsu ¬∑ All rights reserved.  
USE+ Framework‚Ñ¢ is a trademark of Martin Hsu.  
Contact: martin.hsu@martinhsu.digital
